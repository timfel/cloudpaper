\section{Einführung}
\label{sec:einfuehrung}
\IEEEPARstart{H}{eutzutage} betreiben große Firmen eine Vielzahl
von Diensten auf einer großen Anzahl von Servern, möglicherweise in
einem oder mehreren Rechenzentren. Oft laufen Dienste physikalisch
getrennt auf unterschiedlichen Servern, um die Ausfallsicherheit zu
verbessern, außerdem wird Hardware vorgehalten, um fehlerhafte
Komponenten zu ersetzen, \acp{USV} werden eingesetzt, um auch im Falle
eines Stromausfalls nicht offline zu gehen.

\acfp{VM} spielen hier eine große Rolle. Die Technologie zur
Virtualisierung von Hardware existiert seit über 40
Jahren~\cite{tanenbaum1992modern}, die Fähigkeit, mehrere Maschinen
auf einem physikalischen System auszuführen, und Sicherungen ganzer
Betriebszustände zu erstellen ermöglichen es Dienstanbietern, Ausfälle
zu isolieren und schnell zu beheben und deshalb können Versprechen von
99.9\% Verfügbarkeit an alle Kunden gegeben
werden~\cite{google-app-sla}.


Mit dem Aufkommen von Cloud Anbietern hat sich ein
Dienstleistungssektor etabliert, der sich voll und ganz mit dem Ziel
"`100\% Uptime"' beschäftigt. Diese Clouds, privat oder öffentlich,
sind für Unternehmen zunehmend interessant, da sie die physikalische
Hardware von der Ausführungsumgebung von Diensten zunehmend
entkoppelt. Für Unternehmen ist der Schritt schon heute aufgrund eines
potentiell geringeren administrativen Aufwands interessant,
Rechenleistung kann bereitgestellt werden. Doch egal wie abstrahiert,
auch \acp{VM} laufen letzten Endes auf physikalischer Hardware, und
diese kann ausfallen. Um dem "`100\% Uptime"'-Ziel nahe zu kommen,
müssen Dienste nicht nur virtualisiert werden, sondern auch frei
zwischen Servern und Rechenzentren bewegt werden können. Hierfür sind
in den letzten Jahren mehrere Lösungen auf den Markt gekommen, nachdem
im Jahr 2002 erstmals erfolgreich eine virtualisiert laufendes System
ohne herunterfahren auf einen anderen Server migriert wurde.




% \paragraph*{Mögliche Probleme}
% \label{sec:mogliche-probleme}

% \onlydraft{- Probleme:
%   - Ungleichmäßige Auslastung
%   - Wartungskosten (Admins)
%   - Downtime bei Upgrades/HW-Problemen
%   - Operationskosten (Strom)
% }

% Beim traditionellen Betrieb eines Rechenzentrums können jedoch
% wirtschaftliche Probleme auftreten. 

\subsection{Der Status in Rechenzentren}

Das Aufstocken von Hardware oder reagieren auf Hardware-Probleme ist
Tagesgeschäft in Rechenzentren. Nichtsdestoweniger sind
\emph{Ausfallzeiten} bei solchen Arbeiten unvermeidbar, sofern man
nicht mit Grid- oder Clustertechnologie arbeitet. 

Ein Server ist dann für den Betreiber am effizientesten, wenn er
möglichst ausgelastet ist~\cite{Schwarzer2010:Cloud-Hype-Tren}. Nun
ist bei vielen Anwendungen, die auf solchen Servern laufen mit
Lastspitzen aus den verschiedensten Gründen zu rechnen, wie das
Verarbeiten von Batch-Jobs am Monatsende, das bei vielen
\ac{ERP}-Systemen üblich ist. Auch das plötzliche Bekanntwerden vorher
eher unbekannter Anwendungen (insbesondere Webseiten), bekannt als
\emph{Slashdot effect}~\cite{halavais2001slashdot}, kann solche
Lastspitzen auslösen. Während erstere planbar sind, können letztere
unerwartet auftreten. Aus diesem Grund muss dafür Sorge getragen
werden, dass für Lastspitzen ausreichend Pufferkapazitäten vorhanden
sind. Eine \emph{gleichmäßig hohe Auslastung} ist damit traditionell
kaum möglich, selbst wenn Anwendungen in einem Cluster betrieben
werden.

Das Betreiben von Servern zieht neben den Beschaffungskosten noch
\emph{laufende Kosten} nach sich, abgesehen von Software sind das
insbesondere Strom und gegebenenfalls Kosten aus Wartungsverträgen.
Auch das Personal, das die Server betreibt, ist zu bezahlen.
\medskip

Anbieter von Cloud-Computing-Platformen argumentieren, dass die
genannten Probleme durch ihre Platformen zumindest in großen Teilen
gelöst wird\cite{heroku,engineyard,openstack}. Insbesondere wenn es um
Infrastruktur, also Betriebssysteme etc., als Dienst geht, ist die
Virtualisierung dieser Infrastruktur die Grundlage, um einen solchen
Cloud-Dienst bereitzustellen.\cite{nomadbioslivemigration-cloudseminar}.







\subsection{Cloud-Computing und Virtualisierung}
\label{sec:ziel}

\onlydraft{- Public vs Private
Für potentielle Nutzer einer Cloud Lösung präsentieren sich derzeit
zwei Möglichkeiten: Eine eigene, business-interne Cloud Plattform zu
installieren, oder 

In this part we will explore the state of the art in live VM
migration, both from a technical as from a use-case point of view.
Ich will scalieren:
\begin{itemize}
\item Public Cloud
\item Private Cloud
\end{itemize}
- Um zu entscheiden zunächst wissen, {\bf was} in die cloud geht
}

Wenn es um Cloud-Computing und Virtualisierung geht, stellt sich die
Frage, was an sich Virtualisiert werden soll und überhaupt mit
Cloud-Computing unterstützbar ist. Neben der Frage nach dem Was, ist
auch interessant, wo zwischen Systemplatine und Endbenutzeranwendung
Virtualisierung stattfinden kann. Dies soll im Folgenden beleuchtet werden.


\subsubsection{Level der Virtualisierung}
\label{sec:def-virtualisierung}

\begin{figure*}[htbp]
  \centering
  \includegraphics[width=\textwidth]{images/Virtualisierungslevel}
  \caption{Virtualisierung kann auf verschiedenen Ebenen angesetzt werden. Im Kontext von Live-Migration sind die vertikal eingezeichneten Elemente, das heißt, die zu virtualisierenden Betriebssysteme oder Applikationen von Interesse. }
  \label{fig:levels}
\end{figure*}

Virtualisierung kann auf verschiedenen Ebenen stattfinden. Je näher an
der Hardware die Virtualisierung stattfindet, desto mehr kann die
Hardware auch unterstützend wirken. Je ferner der Hardware, desto
weniger ist die Virtualisierung von der unterliegenden Hardware
abhängig.~\cite{Giesekus2010:Virtualisierung} In diesem Zusammenhang
beschreiben \emph{Konsolidierung} (insb. Server-Konsolidierung),
\emph{Separation} und \emph{Virtualisierung} verschiedene Perspektiven
auf den selben Sachverhalt: \emph{Das Nebeneinanderbetreiben von
Ausführungsumgebungen auf ein und derselben physischen Recheneinheit
ohne (oder mit minimaler) gegenseitige(r) Kenntnis.}

In der untersten Schicht kann die so genannte
\emph{Systempartitionierung} betrachtet werden (Siehe zu den Ebenen
\autoref{fig:levels}). Die "`Sun Fire Dynamic System
Domains"'~\cite{Shoumack2007:Beginners-Guid-}, die auf Sun Fire
Servern zur Verfügung steht, ist ein Beispiel für diesen
Virtualisierungsansatz. Die Hardware dieser Server ist in der Lage,
verschiedene Ausführungsumgebungen, das heißt, Betriebssysteme,
elektronisch isoliert zu betreiben. Es bedarf keinerlei Unterstützung
in den darüberliegenen Frimware- oder Softwareschichten. Diese Art
Virtualisierung kommt der Ausführung auf physikalisch getrennten
Rechnern am nächsten.

Eine Ebene höher kann Virtualisierung mit Hilfe von
\emph{Hypervisoren} betrieben werden. \acfp{VM} laufen auf
physikalischen Maschinen durch einen \emph{Hypervisor}, ein minimales
Betriebssystem, dass den Zugriff auf die physikalische Hardware regelt
und Routing zwischen dem physikalischen und virtuellen Netzwerk
bereitstellt~\cite{tanenbaum1992modern}. Wenn eine \ac{VM} ausfällt,
bleiben die anderen davon unbeeinflusst. Da des weiteren alle
Operationen innerhalb einer \ac{VM} virtualisiert sind, kann der Hypervisor
den Zustand eines virtuellen Servers in regelmäßigen Abständen
sichern, und so bei Ausfall die \ac{VM} von einer früheren Sicherung
wiederherstellen. Beispiele für Hypervisorvirtualisierung sind VMWare
ESXi und damit auch vSphere~\cite{:Free-VMware-vSp} und Xen~\cite{Barham:2003:XAV:945445.945462}.

Ein Speziallfall der Virtualisierung mit Hypervisoren sind die
\emph{\acfp{ldom}}, die auf Rechnern mit Prozessoren der SPARC T-Serie
zur Verfügung stehen und unter dem Namen "`Oracle VM Server for
SPARC"'~\cite{Corporation:Oracle-VM-Serve} von Oracle vermarktet
werden. Dabei können die Ressourcen des Rechners in logische Bereiche
(\aclp{ldom}) eingeteilt werden, die gleichzeitig jeweils ein
Betriebssystem zur Verfügung stellen können. Damit ist es möglich,
ohne direkte Software-Unterstützung eine virtualisierte Ausführung
von Betriebssystemen zu haben: die Firmware der SPARC-Rechner stellt
Überwachungs- und Steuerungsfunktionalität bereit, die Hypervisoren
nicht unähnlich ist.

Auf Betriebssystemebene ist ebenfalls eine Art Virtualisierung
möglich. Dabei ist das Ziel, mehrere Exemplare der selben
Betriebssysteminstallation auszuführen. Ein Beispiel für diese
\emph{Betriebssystempartitionierung} (auch \emph{Servervirtualisierung
  auf Betriebssystemebene}) sind die "`Solaris
Zones"'~\cite{price2004solaris}. Sie erlauben, eine
Solaris-Installation mehrfach ausführen zu lassen, und zu einem
gewissen, einstellbaren Grad die installierten
Betriebssystemkomponenten nachzunutzen respektive zu ersetzen. Dabei
wird der Betriebssystemkern einmal ausgeführt, trägt aber Sorge dafür,
den einzelnen Zonen als "`ihr"' Kern zu erscheinen. Eine vergleichbare
Technologie für Linux-Systeme ist das
OpenVZ-Projekt~\cite{ahmed2008server}.

Auf Applikationsebene gibt es zwei unterschiedliche
Virtualisierungsansätze. Während \emph{Desktopvirtualisierung},
vergleichbar zur Hypervisorvirtualisierung, Betriebssysteme
virtualisiert und somit innerhalb eines anderen Betriebssystem bereit
stellt, haben Prozess-\acp{VM} das Ziel, eine Ausführungsumgebung für
bestimmte Programmiersprachen oder Applikationen bereit zu stellen.
Beispiele für ersteres sind VMWare
Workstation~\cite{VMWare-Inc:VMware-Workstat} oder Oracle
VirtualBox~\cite{Oracle-Corporation:VirtualBox} (vormals Sun xVM), für
letzteres \acp{VM} wie die
JVM~\cite{Sun-Developer-Network2003:The-Java-Virtua} oder
Smalltalk-Implementierungen~\cite{ansiSmalltalk}.

\subsubsection{Cloud-Computingansätze}

\onlydraft{Auf welchen Ebenen gibt es "`Clouds"', welche Ebene betrachten wir,
PaaS vs IaaS.}

Bei Betrachtung der verschiedenen Ebenen, auf denen Virtualisierung
von Ausführungsumgebungen möglich ist, stellt sich die Frage, welche
davon sich als "`Cloud-Ebene"' eignen.~\cite{Gebhart2010:Virtualization-}
\begin{description}[\IEEEsetlabelwidth{PaaS}]
\item[SaaS] Auf Applikationsebene (vgl. \autoref{fig:levels}) können
  Anwendungen in "`Cloud-Manier"' bereit gestellt werden. Der Anbieter
  der \acfi{SaaS}-Lösung hält dafür (zumeist mehrere) Installationen
  einer Anwendung bereit, die von Kunden genutzt werden können, ohne
  irgendeinen Installationsaufwand für die Anwendung beim Kunden zu
  haben. Ein Beispiel für solche Clouds ist
  Google~Apps~\cite{Google-Apps}, womit \zB Büroapplikationen (neben
  anderen) als Dienst angeboten werden.

  Im Zusammenhang mit \ac{SaaS} ist Live-Migration zumeist
  uninteressant; wo eine Anwendung läuft spielt in diesem Zusammenhang
  eine untergeordnete Rolle. Auf Anbieterseite kann Migration und
  Live-Migration ein Thema sein, ist aber von Anwendung zu Anwendung
  gesondert zu Betrachten. Für einzelne Anwendungen kommt
  gegebenenfalls Prozessmigration in Frage, bei komplexeren, viele
  Prozesse umspannenden Anwendungen wird zumeist die Migration der
  unterliegenden Ausführungsumgebung, insbesondere Betriebssystem,
  vorgezogen (vgl.~IaaS).
\item[PaaS] Auch auf Applikationsebene, ist bei \acfi{PaaS} nicht eine
  Anwendung, sondern eine Platform Gegenstand. Nutzer dieser Clouds
  bekommen so eine Art Middleware oder Ausführungsumgebungen
  bestimmter Programmiersprachen bereit gestellt, zum Teil auch
  Entwicklungsumgebungen. Beispielsweise stellt Google mit
  App~Engine~\cite{Google-App-Engi} eine JVM-basierte
  Ausführungsumgebung bereit, auf die die Nutzer ihre eigenen
  Webanwendungen ausliefern können.
  
  An sich ist \ac{PaaS} eine spezialisierte Form von \ac{SaaS}, nur
  der bereitgestellte Dienst ist insbesondere eine
  Ausführungsumgebung. Auch hier ist Live-Migration weniger relevant;
  Nutzer, die ihre Anwendungen bei einem \ac{PaaS}-Anbieter laufen
  lassen, unterscheiden sich kaum von Nutzern, die eine
  \ac{SaaS}-Anwendung nutzen: wo die Anwendung läuft ist kaum
  interessant. Für Anbieter bietet sich wieder Prozessmigration an
  oder, je nach angebotener Platform, traditionelle ausfalltolerante,
  lastverteilungsbasierte Konfigurationen der Platform.
\item[IaaS] Die Idee hinter \acfi{IaaS} ist, im Gegensatz zu den
  vorigen Ansätzen, komplette Ausführungsumgebungen im Sinne von
  Betriebssystemen auf Nachfrage zur Verfügung zu stellen. Damit ist
  \ac{IaaS} die Ebene, auf der Virtualisierung im hier vorgestellten
  Sinn genutzt wird. Anbieter und Kunden von \ac{IaaS}-Diensten
  können ein Interesse daran haben, den Ort, an dem der Dienst /das
  Betriebssystem, ausgeführt wird, zu wechseln. Damit kann einerseits
  die Hardware gemeint sein, auf der das Betriebssystem läuft,
  andererseits auch der geographische Ort an dem die Hardware steht.
  Anforderungen wie
  \begin{itemize}
  \item schnelles Bereitstellen von neuen Betriebssysteminstanzen,
  \item Vorsorge für Lastspitzen und
  \item schnelle, dynamische Hardwareanpassung
  \end{itemize}
  machen \ac{IaaS} zur eigentlichen Schnittstelle zwischen
  Virtualisierung und Cloud-Computing.

  Interessanterweise ist für das Bereitstellen von \ac{IaaS}-Diensten
  mit Hilfe von virtualisierten Betriebssystemen vom Ansatz her nicht
  relevant, welches Virtualisierungslevel (vgl.
  \autoref{fig:levels}) dafür genutzt wird. Praktisch hat es jedoch
  schon Auswirkungen, ob ein \ac{IaaS}-Dienst auf Grundlage von
  VirtualBox, VMWare ESXi oder Oracle Dynamic System Domains betrieben wird.
\end{description}

Live-Migration im Kontext von Cloud-Computing ist somit hauptsächlich
bei \ac{IaaS}  anzutreffen. Entsprechend wird im Folgenden vorrangig
\ac{IaaS} besprochen.


\subsection{Herausforderungen des Cloud-Computing}
\onlydraft{Probleme:
\begin{itemize}
\item Public
  \begin{itemize}
  \item Bindung an Provider
  \item Scalierbedarf zunächst unklar -> Kostenfrage
  \item Physikalischer Ort der Daten unbekannt -> VMs müssen in die
    private Cloud oder in Rechenzentren verschoben werden können ->
    gesetzl. Vorschriften, Intellectual Property, \ldots
  \end{itemize}
\item Private
  \begin{itemize}
  \item Scalierbedarf gegen Wartungsaufwand -> Menge der HW
  \item Gleichmäßige Auslastung zunächst genauso schwierig wie vorher
  \item Hardware-Wechsel soll nicht mehr zu Donwtime führen
  \item Virtualisierung 
  \end{itemize}
\end{itemize}
}

Oft wird in letzter Zeit, wenn der Begriff Cloud-Computing benutzt
wird, zwischen \emph{public cloud} und \emph{private cloud}
unterschieden. Zur \emph{public cloud} gehören alle Anbieter von
Cloud-Diensten, von \ac{SaaS} bis \ac{IaaS}, die auf dem Markt
auftreten; im Gegensatz dazu sind \emph{private clouds} an ein
Unternehmen -- oder Betreiber -- gebunden und im Normalfall der
Öffentlichkeit nicht zugänglich ~\cite{Wagener2010:Cloud-Computing}.
Zumeist geht es bei dieser Weise, Cloud-Computing zu betreiben, um
\ac{IaaS}. Die Idee der \emph{private cloud} hat sich in den letzten
Jahren aus dem bis dahin im Allgemeinen öffentlichen, das heißt, durch
nich-unternehmenseigene Firmen betrieben, Cloud-Computing gebildet:
Unternehmen, die die Vorteile davon nutzen wollten, hatten gewisse
Herausforderungen zu bewältigen.

\paragraph*{Anbieterbindung}
\label{sec:anbieterbindung}

Wählt ein Unternehmen einen bestimmten Cloud-Computing-Anbieter, heißt
das bis dato, sich langfristig an diesen zu binden. Proprietäre oder
zumindest inkompatible Cloud-Computing-Platformen machen ein
zukünftiges Wechseln schwierig, von Live-Migration von Anbieter zu
Anbieter ganz zu Schweigen. 

\paragraph*{Anforderungen an den Standort}
\label{sec:anforderungen-an-den}

Aufgrund gesetzlicher Bestimmungen ist es bisweilen notwendig,
sicherzustellen, das die Verarbeitung bestimmter Daten an einem
gestimmten geographischen Ort stattfindet, \zB einem bestimmten
Staatsgebiet. Bei \emph{public cloud}-Betreibern ist es zumeist nicht
möglich das zu gewährleisten. Sollte das doch der Fall sein, kann ein
Unternehmen trotzdem Interesse daran haben, das zumindest bestimmte
Teile der Datenverarbeitung "`innerhalb"' des Unternehmens
stattfinden.

\medskip

Das einrichten von in Cloud-Manier betriebenen Rechenzentren in
Unternehmen, führt nun dazu, dass diese beiden Probleme angegangen
werden können, das Unternehmen betreibt nun eine \emph{private cloud}.
Es bleiben jedoch noch Herausforderungen, die der privaten und der
öffentlichen Variante gemein sind oder gar durch das private Betreiben
hinzukommen.~\cite{Schwarzer2010:Cloud-Hype-Tren}

\paragraph*{Skalierungsplanung}
\label{sec:skalierungsplanung}

Bei den meist als Entwicklungsprojekten betriebenen
Cloud-Computing-Anwendungen ist für Unternehmen oft im Vorhinein nicht
klar, wie stark eine Skalierung später notwendig ist. Zumeist
\ac{IaaS}-Projekte, birgt eine zu sparsame Konfiguration das Risiko,
nicht schnell genug auf Lastspitzen reagieren zu können, wenn das
Projekt plötzlich sehr stark genutzt
wird~\cite{flightcaster_success}. Andersherum kann eine zu großzügige
Konfiguration zu kostenintensiv sein, ob nun \emph{private} oder
\emph{public}. Anpassbare \ac{IaaS}-Konfigurationen sind daher
wünschenswert. Im Rahmen von Betriebssystemvirtualisierung mit
\acfp{VM} ist das auch durchführbar, stößt aber auch an seine Grenzen:
benötigt eine \ac{VM} plötzlich weit mehr Speicher als vorher, weil
\zB die Datenbank des betriebenen Projektes stark vergrößert wurde,
ist die Grenze der Speicher, der physisch verfügbar ist. Wachsen die
Anforderungen darüber hinaus, kann das Verschieben der \ac{VM} auf
Hardware mit mehr Speicher Abhilfe schaffen. Live-Migration kann hier
helfen, Ausfallzeiten gering zu halten.

\paragraph*{Auslastungsplanung}
\label{sec:auslastungsplanung}

Eine Herausforderung, auf die Cloud-Computing konzeptuell überhaupt
reagieren sollte, ist, die vorhandene Hardware bestmöglich, das heißt,
gleichmäßig hoch auszulasten. Nutz man öffentliche Cloud-Anbieter, ist
das für ein Unternehmen als Kunden kein Problem, bei privat
betriebenen Clouds muss das jedoch bedacht werden. Das Konsolidieren
von sonst einzelnen Betriebssystem auf einen Server mittels
Virtualisierung ist eine Möglichkeit, eine verbesserte Auslastung von
Hardware zu ermöglichen. Auslastungsplanung und Konsolidierung ist
jedoch auch im Kontext von Skalierungsplanung zu betrachten. Das
heißt, dass hier normalerweise eine Abwägung zwischen guter Auslastung
und Lastspitzensicherheit geschehen muss. Live-Migration von \acp{VM}
kann helfen, beides in gewisser Weise zu ermöglichen: Wird eine
\ac{VM} unter Normalbedingungen zusammen mit anderen auf einer
Hardware betrieben, ist es doch möglich, bei Lastspitzen die \ac{VM}
auf eine andere, gegebenenfalls eigene, Hardware zu verschieben.

\paragraph*{Wartung}
\label{sec:wartung}

In jedem Rechenzentrum gehört der Ausfall von Hardware, aber auch das
Aufstocken oder Austauschen dieser zum Tagesgeschäft. Dies ist im
Normalfall mit Ausfallzeiten verbunden. Das Verschieben von \acp{VM}
auf andere Hardware und nachfolgende Wartungsarbeiten an der
Vorherigen hilft, Ausfallzeiten zu minimieren.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "FelgentreffPape_2010_Live-MigrationInVirtuellenUmgebungen"
%%% End: 
