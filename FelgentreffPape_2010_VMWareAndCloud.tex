\documentclass{scrartcl}

%\let\ifdebug\iftrue
\let\ifdebug\iffalse

\usepackage{style}
\usepackage{blindtext}
\bibliographystyle{alpha}

\title{Live VM Migration technology for Cloud hosting providers}
\subtitle{Ab inne cloud}
%\authoremail{Tim Felgentreff \and Tobias Pape}{\{firstname.lastname\}@student.hpi.uni-potsdam.de}
\author{Tim Felgentreff \and Tobias Pape}

\begin{document}
\maketitle
\tableofcontents

\section{Introduction}
\label{sec:introduction}
Today, many organizations deploy a multiude of services on a large
number of servers. In some cases, all these services run on different
machines not because one machine cannot handle the load, but for
reasons of reliability.  All software is faulty\cite{Zeller2006}, and
operating systems with thousands of lines of code, running servers
written by different software vendors simply cannot be trusted to
provide uptimes of 99.9 percent. Putting each service on a separate
machine will achieve reliablity at the expense of maintainability
simply because a large number of physical machines is involved.

Virtual machine technology has been around for more than 40
years\cite{tanenbaum1992modern}. The technology to host multiple
machines on a single system reduces the space and power requirements
for data centers and represents enormous cost savings for companies
like Amazon, Microsoft or Google, which deploy hundreds or thousands
of servers for a variety of services. Unsurprisingly, virtualization
for cost reduction and transparent scalability is becoming
increasingly popular.

This trend, however, seems to contradict the reliability requirements
mentioned above. We will discuss how virtualization solutions solve
their reliability issues and how cloud providers such as Amazon,
Rackspace or Engine Yard are able to guarantee uptimes of 99.9 percent
to the third of fourth decimal value.

\section{State of the Art}
\label{sec:sota}

\paragraph{What are the reliability implications of running virtual machines on a single
physical node?}

Running a large number of virtual machines (VMs) on very few physical
nodes seems like betting all your money on one horse only. If one
physical node fails a number of services will be unavailable all at
once, probably much more than if a dedicated machine would
crash. However, most server failures in data centers are due to buggy
software, especially operating systems and servers, not hardware
failure. Virtualization isolates such failures, because VMs run in an
isolated environment atop a \emph{hypervisor}.

A hypervisor controls access to the physical hardware, provides
routing from the physical network into the virtual network and
isolates machines from one another. If any one machine should fail,
all others will be unaffected. Because all of the operations within a
VM are virtualized, the hypervisor can checkpoint virtual servers at
regular intervals. Should a VM fail, it can be restored from an
earlier checkpoint and resume operations.

Critical services can be run in complete isolation to minimize the
potential for failure due to faulty or incompatible software
stacks. The hypervisor itself is the only software running in kernel
mode on the physical machine and has orders of magnitude fewer lines
of code than the average operating system. This means it is equally
less likely to encounter a bug in it's programming.

Still, hardware failure, while less likely than software bugs, are an 
issue that has to be considered.

\subsection{VMWare and Livemigration}
\label{sec:vmware}

\blindtext

\subsection{Bla}
\label{sec:bla}

\blindtext

\ParSep

\blindtext

\section{Ble}
\label{sec:ble}

Ble

\begin{code}[language=SQL]
select  * from foo where true;
\end{code}
\spacedlowsmallcaps{TheFooTest}
\spacedallcaps{test}
\blinddocument

%\bibliography{timfelgentreff}
\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
